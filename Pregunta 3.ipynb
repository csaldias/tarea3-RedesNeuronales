{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pregunta 3 T3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "q3G1xGWoin-Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Pregunta 3: Desafío Kaggle"
      ]
    },
    {
      "metadata": {
        "id": "iSeTOLqLitLE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Obtención de los datos"
      ]
    },
    {
      "metadata": {
        "id": "_6V0SdmxAYO1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "En esta sección se instala la utilidad de lína de comandos de Kaggle, se configuran las credenciales de acceso y se obtienen los datos de entrenamiento y pruebas del desafío."
      ]
    },
    {
      "metadata": {
        "id": "M6ry6FqKbnds",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Eyy4nP61fU2Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "outputId": "2ad75d28-d396-4b9f-ee3c-3324c72becd8"
      },
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle\n",
        "!wget -O ~/.kaggle/kaggle.json http://vps.csaldias.cl/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 308,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "--2018-08-31 21:07:22--  http://vps.csaldias.cl/kaggle.json\n",
            "Resolving vps.csaldias.cl (vps.csaldias.cl)... 170.239.86.99\n",
            "Connecting to vps.csaldias.cl (vps.csaldias.cl)|170.239.86.99|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 64 [application/json]\n",
            "Saving to: ‘/root/.kaggle/kaggle.json’\n",
            "\n",
            "/root/.kaggle/kaggl 100%[===================>]      64  --.-KB/s    in 0s      \n",
            "\n",
            "2018-08-31 21:07:22 (6.13 MB/s) - ‘/root/.kaggle/kaggle.json’ saved [64/64]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-A3WEZ9thSsY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "0ea51954-7900-4813-bfa0-a6fef9214dda"
      },
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c tareaANN"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading labels_train.csv to /content\r\n",
            "\r  0%|                                               | 0.00/11.9k [00:00<?, ?B/s]\r\n",
            "100%|██████████████████████████████████████| 11.9k/11.9k [00:00<00:00, 6.85MB/s]\n",
            "Downloading sample_submision.csv to /content\n",
            "  0%|                                               | 0.00/2.25k [00:00<?, ?B/s]\n",
            "100%|██████████████████████████████████████| 2.25k/2.25k [00:00<00:00, 1.93MB/s]\n",
            "Downloading images_test.npy to /content\n",
            " 96%|██████████████████████████████████████▌ | 339M/352M [00:04<00:00, 43.7MB/s]\n",
            "100%|████████████████████████████████████████| 352M/352M [00:04<00:00, 81.2MB/s]\n",
            "Downloading images_train.npy to /content\n",
            "100%|██████████████████████████████████████▉| 1.37G/1.37G [00:10<00:00, 111MB/s]\n",
            "100%|███████████████████████████████████████| 1.37G/1.37G [00:10<00:00, 139MB/s]\n",
            "Downloading frames_test.tar.gz to /content\n",
            " 54%|████████████████████▋                 | 9.00M/16.5M [00:00<00:00, 24.0MB/s]\n",
            "100%|██████████████████████████████████████| 16.5M/16.5M [00:00<00:00, 35.9MB/s]\n",
            "Downloading frames_train.tar.gz to /content\n",
            " 91%|██████████████████████████████████▌   | 60.0M/66.0M [00:00<00:00, 71.8MB/s]\n",
            "100%|███████████████████████████████████████| 66.0M/66.0M [00:00<00:00, 112MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rcCq1Se7h2yZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "b6bb6e59-3069-4a8d-9e5f-5be8e625c500"
      },
      "cell_type": "code",
      "source": [
        "!ls -lh"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 1.8G\r\n",
            "-rw-r--r-- 1 root root  17M Aug 31 18:34 frames_test.tar.gz\r\n",
            "-rw-r--r-- 1 root root  66M Aug 31 18:34 frames_train.tar.gz\r\n",
            "-rw-r--r-- 1 root root 352M Aug 31 18:33 images_test.npy\r\n",
            "-rw-r--r-- 1 root root 1.4G Aug 31 18:34 images_train.npy\r\n",
            "-rw-r--r-- 1 root root  12K Aug 31 18:33 labels_train.csv\r\n",
            "drwxr-xr-x 2 root root 4.0K Aug 30 21:39 sample_data\r\n",
            "-rw-r--r-- 1 root root 2.3K Aug 31 18:33 sample_submision.csv\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "l-Mj2cn0i1jA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Carga y limpieza de los datos"
      ]
    },
    {
      "metadata": {
        "id": "KjE4nJmaAlnB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "En esta sección se importan los datos de entrenamiento, y se realizan los preprocesamientos necesarios."
      ]
    },
    {
      "metadata": {
        "id": "1-cIPmQKiNoj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "x_train = np.load('images_train.npy')\n",
        "df_train = pd.read_csv('labels_train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fA3hXKjHAtmg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "En este caso, decidimos escalar cada imagen a un 25% de su tamaño original, para agilizar el trabajo con la red y reducir su complejidad."
      ]
    },
    {
      "metadata": {
        "id": "BhvBv6ThCqGN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Nosotros hemos decidido abordar este desafío como un problema de clasificación, esto es, la red deberá decidir la categoría a la que pertenece cada imagen que sea probada o evaluada. En este caso, una categoría corresponde a una cantidad determinada de personas en una imagen.\n",
        "\n",
        "Dado que en este dataset existe un máximo de 50 personas en una imagen (al menos en entrenamiento), la red tendrá que discernir entre 51 categorías (de 0 a 50 personas en la imagen, incluídas ambas cantidades)."
      ]
    },
    {
      "metadata": {
        "id": "t5lZa8eGllt8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "from skimage.transform import rescale\n",
        "\n",
        "x_train_rescaled = []\n",
        "for image in x_train:\n",
        "  x_train_rescaled.append(rescale(image, 1.0 / 4.0))\n",
        "x_train_rescaled = np.asarray(x_train_rescaled)\n",
        "\n",
        "y_train = to_categorical(df_train['count'], 51)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x-G56mwD4fge",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c06d806b-edab-4897-d7c0-0b936fc56fe5"
      },
      "cell_type": "code",
      "source": [
        "x_train_rescaled.shape"
      ],
      "execution_count": 366,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1600, 120, 160, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 366
        }
      ]
    },
    {
      "metadata": {
        "id": "7toLdg80hCm1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Definición de la CNN"
      ]
    },
    {
      "metadata": {
        "id": "wrL3VM5vEVLo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "En esta sección se define la arquitectura de la red a utilizar para resolver el desafío."
      ]
    },
    {
      "metadata": {
        "id": "Nac4FaK39Ugs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.constraints import maxnorm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ByAeZI2d9iq9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(128, (5, 5), activation='relu', padding='same', input_shape=x_train_rescaled.shape[1:]))\n",
        "model.add(Conv2D(64, (3, 3), strides=(2, 2), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(64, (3, 3), strides=(2, 2), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(51, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nArZz3nwEaJu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Esta red está basada en la red CNN utilizada con el dataset CIFAR-10 en la Tarea 1 de este curso, con una arquitectura $C \\times C \\times P \\times C \\times C \\times P \\times F \\times F$, dado que (como vimos anteriormente) estas redes tienen un buen desempeño en la clasificación de imágenes. Para este caso en particualr, decidimos adoptar una serie de modificaciones menores a la arquitercura de la red:\n",
        "\n",
        "*  Se añadió una capa de BatchNormalization entre la última capa de pooling y las capas fully-connected, para mejorar el desempeño de la red y reducir las variaciones en el aprendizaje de la red.\n",
        "*   Se añadió una segunda capa densa fully-connected al final de la red, para aumentar el número de parámetros entrenables y mejorar el desempeño sobre el dataset.\n",
        "*   Se modificaron las cantidades de filtros en la primera tanda de capas convolucionales, así como el tamaño del kernel en la primera capa convolucional.\n",
        "*   Se decidió utilizar *strides* en la capa convolucional antes del pooling.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "PQCILIE99ny4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "fbc0c44a-bba9-4f12-bed6-e1661802bc26"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 370,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_23 (Conv2D)           (None, 120, 160, 128)     9728      \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 60, 80, 64)        73792     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 30, 40, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 30, 40, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 30, 40, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 15, 20, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 7, 10, 64)         0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 7, 10, 64)         0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 4480)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 4480)              17920     \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 512)               2294272   \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 51)                26163     \n",
            "=================================================================\n",
            "Total params: 2,758,387\n",
            "Trainable params: 2,749,427\n",
            "Non-trainable params: 8,960\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PFiy6L7ehI2s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Entrenamiento de la CNN"
      ]
    },
    {
      "metadata": {
        "id": "SMVFXMg4G5Ca",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "En esta sección se realiza el entrenamiento de la red creada en la sección anterior."
      ]
    },
    {
      "metadata": {
        "id": "RXOZhgm2RniS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.optimizers import SGD, rmsprop, Adam\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9i6XmIyn9xu4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learning_rate = 0.5\n",
        "decay_rate = 1e-6\n",
        "\n",
        "opt = rmsprop(lr=0.001, decay=1e-6)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fzuq3TeeRaB2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "292e2366-2185-4ad0-cdd8-617425a72684"
      },
      "cell_type": "code",
      "source": [
        "epochs=20\n",
        "batch_size=32\n",
        "history=model.fit(x_train_rescaled, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.1, shuffle=True, verbose=2)"
      ],
      "execution_count": 373,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1440 samples, validate on 160 samples\n",
            "Epoch 1/20\n",
            " - 9s - loss: 3.6053 - acc: 0.0556 - val_loss: 3.2953 - val_acc: 0.0375\n",
            "Epoch 2/20\n",
            " - 8s - loss: 3.4236 - acc: 0.0514 - val_loss: 3.2175 - val_acc: 0.0688\n",
            "Epoch 3/20\n",
            " - 8s - loss: 3.2631 - acc: 0.0667 - val_loss: 5.0410 - val_acc: 0.0250\n",
            "Epoch 4/20\n",
            " - 8s - loss: 3.1079 - acc: 0.0944 - val_loss: 10.2717 - val_acc: 0.0125\n",
            "Epoch 5/20\n",
            " - 8s - loss: 3.0187 - acc: 0.1056 - val_loss: 6.5602 - val_acc: 0.0125\n",
            "Epoch 6/20\n",
            " - 8s - loss: 2.8412 - acc: 0.1396 - val_loss: 4.4919 - val_acc: 0.0375\n",
            "Epoch 7/20\n",
            " - 8s - loss: 2.7251 - acc: 0.1556 - val_loss: 8.9038 - val_acc: 0.0063\n",
            "Epoch 8/20\n",
            " - 8s - loss: 2.5804 - acc: 0.1882 - val_loss: 6.2819 - val_acc: 0.0000e+00\n",
            "Epoch 9/20\n",
            " - 8s - loss: 2.3416 - acc: 0.2576 - val_loss: 7.6474 - val_acc: 0.0000e+00\n",
            "Epoch 10/20\n",
            " - 8s - loss: 2.1037 - acc: 0.3250 - val_loss: 4.7859 - val_acc: 0.0250\n",
            "Epoch 11/20\n",
            " - 8s - loss: 1.8862 - acc: 0.3903 - val_loss: 10.3505 - val_acc: 0.0437\n",
            "Epoch 12/20\n",
            " - 8s - loss: 1.6911 - acc: 0.4625 - val_loss: 9.6383 - val_acc: 0.0063\n",
            "Epoch 13/20\n",
            " - 8s - loss: 1.4037 - acc: 0.5181 - val_loss: 10.5199 - val_acc: 0.0000e+00\n",
            "Epoch 14/20\n",
            " - 8s - loss: 1.1606 - acc: 0.6236 - val_loss: 7.7945 - val_acc: 0.0063\n",
            "Epoch 15/20\n",
            " - 8s - loss: 0.9829 - acc: 0.6785 - val_loss: 4.4536 - val_acc: 0.0813\n",
            "Epoch 16/20\n",
            " - 8s - loss: 0.8092 - acc: 0.7278 - val_loss: 12.9183 - val_acc: 0.0063\n",
            "Epoch 17/20\n",
            " - 8s - loss: 0.6476 - acc: 0.7840 - val_loss: 9.7099 - val_acc: 0.0187\n",
            "Epoch 18/20\n",
            " - 8s - loss: 0.5614 - acc: 0.8090 - val_loss: 6.2765 - val_acc: 0.0437\n",
            "Epoch 19/20\n",
            " - 8s - loss: 0.4543 - acc: 0.8507 - val_loss: 6.4282 - val_acc: 0.0375\n",
            "Epoch 20/20\n",
            " - 8s - loss: 0.3937 - acc: 0.8653 - val_loss: 6.3091 - val_acc: 0.0563\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QoZTP2rCHoqP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "1c9ce4bb-aac5-474a-d359-569200a8bf9e"
      },
      "cell_type": "code",
      "source": [
        "epochs=5\n",
        "batch_size=32\n",
        "history=model.fit(x_train_rescaled, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.1, shuffle=True, verbose=2)"
      ],
      "execution_count": 378,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1440 samples, validate on 160 samples\n",
            "Epoch 1/5\n",
            " - 8s - loss: 0.1825 - acc: 0.9472 - val_loss: 11.8548 - val_acc: 0.0938\n",
            "Epoch 2/5\n",
            " - 8s - loss: 0.1621 - acc: 0.9507 - val_loss: 6.1652 - val_acc: 0.1125\n",
            "Epoch 3/5\n",
            " - 8s - loss: 0.1542 - acc: 0.9493 - val_loss: 6.3710 - val_acc: 0.0813\n",
            "Epoch 4/5\n",
            " - 8s - loss: 0.1464 - acc: 0.9479 - val_loss: 12.6346 - val_acc: 0.0312\n",
            "Epoch 5/5\n",
            " - 8s - loss: 0.1153 - acc: 0.9667 - val_loss: 7.5933 - val_acc: 0.0750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5JIvt0IGhMvb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Pruebas sobre la Red"
      ]
    },
    {
      "metadata": {
        "id": "9pP-Vb-ZH1_k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Como una medida del desempeño aproximado de la red, medimos el error RMSE sobre el dataset de entrenamiento completo."
      ]
    },
    {
      "metadata": {
        "id": "h_38Xv8HUGLj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Y_trained = model.predict(x_train_rescaled,batch_size=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ns-XbCPTa2Ww",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_trained_argmax = []\n",
        "y_argmax = []\n",
        "for elem in Y_trained:\n",
        "  y_trained_argmax.append(np.argmax(elem))\n",
        "for elem in y_train:\n",
        "  y_argmax.append(np.argmax(elem))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y9CYFsMAduUo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d6a210d1-35e2-4294-bcec-0bb281d48382"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "math.sqrt(mean_squared_error(y_argmax, y_trained_argmax))"
      ],
      "execution_count": 381,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.485555451674558"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 381
        }
      ]
    },
    {
      "metadata": {
        "id": "2dWP0ylcIHMt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ocasionalmente, guardamos el modelo entrenado. Esto nos permitió probar con distintas arquitecturas y volver a otras ya probadas en caso de que algo saliera mal."
      ]
    },
    {
      "metadata": {
        "id": "6NlzI8RjkiYq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save('model-1.485.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DixKZNE8hQ6P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Preparación de Submission a Kaggle"
      ]
    },
    {
      "metadata": {
        "id": "9Vk7YDgRISq5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "El siguiente código importa las imágenes de prueba, realiza el mismo escalado que realizamos para el conjunto de entrenamiento (25% del tamaño original), obtiene las predicciones de la red en base a las imágenes de prueba, y crea el archivo CSV que posteriormente es descargado para ser subido a Kaggle."
      ]
    },
    {
      "metadata": {
        "id": "KRyqfdC2bQqE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_test = np.load('images_test.npy')\n",
        "x_test_rescaled = []\n",
        "for image in x_test:\n",
        "  x_test_rescaled.append(rescale(image, 1.0 / 4.0))\n",
        "x_test_rescaled = np.asarray(x_test_rescaled)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ixqvaKyTb58k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Y_trained = model.predict(x_test_rescaled, batch_size=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A4akxGWZcDB0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_trained_argmax = []\n",
        "for elem in Y_trained:\n",
        "  y_trained_argmax.append(np.argmax(elem))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4GI5HDdkcIDe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_ids = list(range(1, 401))\n",
        "d = {'id': test_ids, 'count': y_trained_argmax}\n",
        "entrega = pd.DataFrame(data=d,columns=['id','count'])\n",
        "entrega.to_csv('submission-1.485.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}